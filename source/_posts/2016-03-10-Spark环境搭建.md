---
title: Spark环境搭建
date: 2016-03-10 20:07:23
tags: spark
categories: 技术
---

# 配置Scala #
SparkMaster上，scala-2.10.4.tgz

	mkdir /usr/lib/scala
	cd /usr/lib/scala
	tar -zxvf scala-2.10.4.tgz

相关的环境变量在.bashrc里已配置。
输入scala -version验证是否成功。
使用scp命令复制到SparkWorker1和SparkWorker2，即可。

# 配置Spark #
SparkMaster上，spark-1.2.0-bin-hadoop2.4.tgz

	mkdir /usr/local/spark
	cd /usr/local/spark
	tar -zxvf spark-1.2.0-bin-hadoop2.4.tgz

相关的环境变量在.bashrc里已配置。

进入spark的conf目录：
![](/images/spark/s_1.png)

第一步修改slaves文件，首先打开该文件，修改为:

	# A Spark Worker will be started on each of the machines listed below.
	SparkWorker1
	SparkWorker2

第二步：配置spark-env.sh
首先把spark-env.sh.template拷贝到spark-env.sh：
cp spark-env.sh.template spark-env.sh

	export JAVA_HOME=/usr/lib/java/jdk1.8.0_25
	export SCALA_HOME=/usr/lib/scala/scala-2.11.4
	export HADOOP_HOME=/usr/local/hadoop/hadoop-2.6.0
	export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
	export SPARK_MASTER_IP=SparkMaster
	export SPARK_WORKER_MEMORY=1g	

SparkWorker1和SparkWorker2采用和SparkMaster完全一样的Spark安装配置，在此不再赘述。采用scp命令复制即可。


# 启动Spark分布式集群并查看信息。 #
第一步：启动Hadoop集群，在SparkMaster使用jps命令，具体操作过程中可以看到如下进程信息：

	root@SparkMaster:/usr/local/hadoop/hadoop-2.6.0/sbin#  ./start-dfs.sh
	root@SparkMaster:/usr/local/hadoop/hadoop-2.6.0/sbin#  ./start-yarn.sh
	root@SparkMaster:/usr/local/hadoop/hadoop-2.6.0/sbin# ./mr-jobhistory-daemon.sh  start historyserver
![](/images/spark/s_2.png)
![](/images/spark/s_3.png)
![](/images/spark/s_4.png)

第二步：启动Spark集群
在Hadoop集群成功启动的基础上，启动Spark集群需要使用Spark的sbin目录下“start-all.sh”：

	root@SparkMaster:/usr/local/spark/spark-1.2.0-bin-hadoop2.4/sbin# ./start-all.sh
![](/images/spark/s_5.png)

此时的SparkWorker1和SparkWorker2会出现新的进程“Worker”：
![](/images/spark/s_6.png)
![](/images/spark/s_7.png)

此时，我们可以进入Spark集群的Web页面，访问“http://SparkMaster:8080”: 如下所示：
![](/images/spark/s_8.png)

从页面上我们可以看到我们有两个Worker节点及这两个节点的信息。
此时，我们进入Spark的bin目录，使用“spark-shell”控制台：

	root@SparkMaster:/usr/local/spark/spark-1.2.0-bin-hadoop2.4/bin# spark-shell
![](/images/spark/s_9.png)

此时我们进入了Spark的shell世界，根据输出的提示信息，我们可以通过“http://SparkMaster:4040” 从Web的角度看一下SparkUI的情况，如下图所示：
![](/images/spark/s_10.png)

同时，我们也可以看一下Executors：
![](/images/spark/s_11.png)


# 测试Spark集群 #

把Spark安装包下的”README.txt”上传到

	root@SparkMaster:/usr/local/spark/spark-1.2.0-bin-hadoop2.4# hadoop fs -put README.md /data 
通过hdfs的web控制台可以发现成功上传了文件：
![](/images/spark/s_12.png)

使用“MASTER=spark://SparkMaster:7077 ./spark-shell”命令启动Spark shell：

	root@SparkMaster:/usr/local/spark/spark-1.2.0-bin-hadoop2.4/bin# MASTER=spark://SparkMaster:7077 ./spark-shell
![](/images/spark/s_13.png)


接下来通过以下命令读取刚刚上传到HDFS上的“README.md”文件 ：

	scala> val file = sc.textFile("hdfs://SparkMaster:9000/data/README.md")
对读取的文件进行以下操作：

	scala> val count = file.flatMap(line => line.split(" ")).map(word => (word,1)).reduceByKey(_+_)

![](/images/spark/s_14.png)
接下来使用collect命令提交并执行Job：
![](/images/spark/s_15.png)
从控制台可以看到我们的程序成功在集群上运行：
![](/images/spark/s_16.png)
![](/images/spark/s_17.png)
![](/images/spark/s_18.png)
![](/images/spark/s_19.png)
上述信息表明程序成功在Spark集群上运行。


# spark的master url #
传递给spark的master url可以有如下几种：

- local 本地单线程
- local[K] 本地多线程（指定K个内核）
- local[*] 本地多线程（指定所有可用内核）
- spark://HOST:PORT 连接到指定的 Spark standalone cluster master，需要指定端口。
- mesos://HOST:PORT 连接到指定的 Mesos 集群，需要指定端口。
- yarn-client客户端模式 连接到 YARN 集群。需要配置 HADOOP_CONF_DIR。
- yarn-cluster集群模式 连接到 YARN 集群 。需要配置 HADOOP_CONF_DIR。

# 提交例子 #
 
	spark-submit --master spark://master:7077   --name JavaWordCountByZch --class org.apache.spark.examples.JavaWordCount --executor-memory 1G --total-executor-cores 2 /home/zch/IdeaProjects/SparkTest/out/artifacts/SparkTest_jar/SparkTest.jar  hdfs://master:9000/data/wordcount

开启远程调试，`--driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8888"`

	spark-submit --master spark://master:7077  --driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8888"  --name JavaWordCountByZch --class org.apache.spark.examples.JavaWordCount --executor-memory 1G --total-executor-cores 2 /home/zch/IdeaProjects/SparkTest/out/artifacts/SparkTest_jar/SparkTest.jar  hdfs://master:9000/data/wordcount